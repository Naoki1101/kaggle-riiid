{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle5\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('../src')\n",
    "import const\n",
    "from utils import DataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nrows = 30_000_000\n",
    "train_df = pd.read_csv('../data/input/train.csv', dtype=const.DTYPE, nrows=nrows)\n",
    "# val_idx = np.load('../data/processed/cv1_valid.npy')\n",
    "\n",
    "# train_df = train_df.iloc[val_idx[np.where(val_idx < nrows)]]\n",
    "# exp_test_df = train_df.groupby('user_id').tail(6)\n",
    "\n",
    "# exp_test_df['group_num'] = 0\n",
    "\n",
    "# for user_id, user_df in exp_test_df.groupby('user_id'):\n",
    "#     user_idx = user_df.index\n",
    "    \n",
    "#     prior_task_id = -1\n",
    "#     group_num = 0\n",
    "#     user_group_array = np.zeros(len(user_df))\n",
    "#     for idx, task in enumerate(user_df['task_container_id']):\n",
    "#         if prior_task_id != task and idx > 0:\n",
    "#             group_num += 1\n",
    "        \n",
    "#         user_group_array[idx] = group_num\n",
    "#         prior_task_id = task\n",
    "        \n",
    "#     exp_test_df.loc[user_idx, 'group_num'] = user_group_array\n",
    "    \n",
    "# exp_test_df['group_num'] = exp_test_df['group_num'].astype(int)\n",
    "\n",
    "# gp = exp_test_df.groupby(['user_id', 'group_num'])\n",
    "\n",
    "# prior_target_dict = {}\n",
    "# for (user_id, group_num), df in gp:\n",
    "#     user_group_id = str(user_id) + '__' + str(group_num + 1)\n",
    "#     prior_target_dict[user_group_id] = df['answered_correctly'].tolist()\n",
    "    \n",
    "# exp_test_df['user_group_id'] = exp_test_df['user_id'].astype(str) + '__' + exp_test_df['group_num'].astype(str)\n",
    "# exp_test_df['prior_group_answers_correct'] = exp_test_df['user_group_id'].map(prior_target_dict)\n",
    "\n",
    "# exp_test_df['user_task_count'] = gp.cumcount()\n",
    "\n",
    "# nan_idx = exp_test_df[exp_test_df['user_task_count'] > 0].index\n",
    "# exp_test_df.loc[nan_idx, 'prior_group_answers_correct'] = np.nan\n",
    "\n",
    "# exp_test_df = exp_test_df.drop(['user_group_id', 'user_task_count'], axis=1)\n",
    "\n",
    "exp_test_df = pd.read_csv('../data/input/example_test.csv')\n",
    "# sub_df = pd.read_csv('../data/team/sub_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>group_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>prior_group_answers_correct</th>\n",
       "      <th>prior_group_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275030867</td>\n",
       "      <td>5729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13309898705</td>\n",
       "      <td>554169193</td>\n",
       "      <td>12010</td>\n",
       "      <td>0</td>\n",
       "      <td>4427</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4213672059</td>\n",
       "      <td>1720860329</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62798072960</td>\n",
       "      <td>288641214</td>\n",
       "      <td>13262</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10585422061</td>\n",
       "      <td>1728340777</td>\n",
       "      <td>6119</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>72400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18020362258</td>\n",
       "      <td>1364159702</td>\n",
       "      <td>12023</td>\n",
       "      <td>0</td>\n",
       "      <td>4424</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2325432079</td>\n",
       "      <td>1521618396</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>39456940781</td>\n",
       "      <td>1317245193</td>\n",
       "      <td>12043</td>\n",
       "      <td>0</td>\n",
       "      <td>5314</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3460555189</td>\n",
       "      <td>1700555100</td>\n",
       "      <td>7910</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2214770464</td>\n",
       "      <td>998511398</td>\n",
       "      <td>7908</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  group_num    timestamp     user_id  content_id  content_type_id  \\\n",
       "0       0          0            0   275030867        5729                0   \n",
       "1       1          0  13309898705   554169193       12010                0   \n",
       "2       2          0   4213672059  1720860329         457                0   \n",
       "3       3          0  62798072960   288641214       13262                0   \n",
       "4       4          0  10585422061  1728340777        6119                0   \n",
       "5       5          0  18020362258  1364159702       12023                0   \n",
       "6       6          0   2325432079  1521618396         574                0   \n",
       "7       7          0  39456940781  1317245193       12043                0   \n",
       "8       8          0   3460555189  1700555100        7910                0   \n",
       "9       9          0   2214770464   998511398        7908                0   \n",
       "\n",
       "   task_container_id  prior_question_elapsed_time  \\\n",
       "0                  0                          NaN   \n",
       "1               4427                      19000.0   \n",
       "2                240                      17000.0   \n",
       "3                266                      23000.0   \n",
       "4                162                      72400.0   \n",
       "5               4424                      18000.0   \n",
       "6               1367                      18000.0   \n",
       "7               5314                      17000.0   \n",
       "8                532                      21000.0   \n",
       "9                393                      21000.0   \n",
       "\n",
       "  prior_question_had_explanation prior_group_answers_correct  \\\n",
       "0                            NaN                          []   \n",
       "1                           True                         NaN   \n",
       "2                           True                         NaN   \n",
       "3                           True                         NaN   \n",
       "4                           True                         NaN   \n",
       "5                           True                         NaN   \n",
       "6                           True                         NaN   \n",
       "7                           True                         NaN   \n",
       "8                           True                         NaN   \n",
       "9                           True                         NaN   \n",
       "\n",
       "  prior_group_responses  \n",
       "0                    []  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "5                   NaN  \n",
       "6                   NaN  \n",
       "7                   NaN  \n",
       "8                   NaN  \n",
       "9                   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/team/riiidFE.pkl', mode='rb') as f:\n",
    "    riiidFE = pickle5.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'compe': {'name': 'riiid-test-answer-prediction'},\n",
    " 'common': {'seed': 2020,\n",
    "  'metrics': {'name': 'auc', 'params': {}},\n",
    "  'drop': ['lecture_idx'],\n",
    "  'debug': False,\n",
    "  'kaggle': {'data': False, 'notebook': False}},\n",
    " 'model': {'backbone': 'transformer_saint_v6_2',\n",
    "  'n_classes': 1,\n",
    "  'epochs': 30,\n",
    "  'params': {'dim_model': 256,\n",
    "   'num_en': 2,\n",
    "   'num_de': 2,\n",
    "   'heads_en': 8,\n",
    "   'heads_de': 8,\n",
    "   'total_ex': 13523,\n",
    "   'total_cat': 7,\n",
    "   'total_tg': 188,\n",
    "   'total_in': 2,\n",
    "   'total_exp': 2,\n",
    "   'seq_len': 121},\n",
    "  'multi_gpu': True,\n",
    "  'head': None},\n",
    " 'data': {'train': {'dataset_type': 'CustomTrainDataset7_2',\n",
    "   'is_train': True,\n",
    "   'params': {'n_skill': 13523, 'max_seq': 121},\n",
    "   'loader': {'shuffle': True, 'batch_size': 512, 'num_workers': 4},\n",
    "   'transforms': None},\n",
    "  'valid': {'dataset_type': 'CustomTestDataset7_2',\n",
    "   'is_train': False,\n",
    "   'params': {'n_skill': 13523, 'max_seq': 121},\n",
    "   'loader': {'shuffle': False, 'batch_size': 512, 'num_workers': 4},\n",
    "   'transforms': None},\n",
    "  'test': {'dataset_type': 'CustomTestDataset7_2',\n",
    "   'is_train': False,\n",
    "   'params': {'n_skill': 13523, 'max_seq': 121},\n",
    "   'loader': {'shuffle': False, 'batch_size': 512, 'num_workers': 4},\n",
    "   'transforms': None}},\n",
    " 'loss': {'name': 'BCEWithLogitsLoss', 'params': {}},\n",
    " 'optimizer': {'name': 'Adam', 'params': {'lr': 0.001}},\n",
    " 'scheduler': {'name': 'CosineAnnealingLR', 'params': {'T_max': 30}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_content_map_dict():\n",
    "    questions_df = pd.read_csv(f'{const.INPUT_DATA_DIR}/questions.csv')\n",
    "    q2p = dict(questions_df[['question_id', 'part']].values)\n",
    "    q2p = np.array(list(q2p.values()))\n",
    "    \n",
    "    questions_df['tags'] = questions_df['tags'].fillna(0)\n",
    "    questions_df['tag_list'] = questions_df['tags'].apply(lambda tags: [int(tag) for tag in str(tags).split(' ')])\n",
    "    questions_df['tag_list'] = questions_df['tag_list'].apply(lambda x: [188] * (6 - len(x)) + x)\n",
    "    q2tg = dict(questions_df[['question_id', 'tag_list']].values)\n",
    "    q2tg = np.array(list(questions_df['tag_list'].values))\n",
    "    return q2p, q2tg\n",
    "q2p, q2tg = make_content_map_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "# https://github.com/arshadshk/SAINT-pytorch/blob/main/saint.py\n",
    "class Feed_Forward_block(nn.Module):\n",
    "    \"\"\"\n",
    "    out =  Relu( M_out*w1 + b1) *w2 + b2\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_ff):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=dim_ff, out_features=dim_ff)\n",
    "        self.layer2 = nn.Linear(in_features=dim_ff, out_features=dim_ff)\n",
    "\n",
    "    def forward(self, ffn_in):\n",
    "        return self.layer2(F.relu(self.layer1(ffn_in)))\n",
    "\n",
    "\n",
    "class Encoder_block(nn.Module):\n",
    "    \"\"\"\n",
    "    M = SkipConct(Multihead(LayerNorm(Qin;Kin;Vin)))\n",
    "    O = SkipConct(FFN(LayerNorm(M)))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_model, heads_en, total_ex, total_cat, total_tg, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len - 1\n",
    "        self.embd_ex = nn.Embedding(total_ex, embedding_dim=dim_model)\n",
    "        self.embd_cat = nn.Embedding(total_cat + 1, embedding_dim=dim_model)\n",
    "        self.embd_tg = nn.Embedding(total_tg + 1, embedding_dim=dim_model)\n",
    "        self.embd_pos = nn.Embedding(seq_len, embedding_dim=dim_model)\n",
    "        self.dt_fc = nn.Linear(1, dim_model, bias=False)\n",
    "        # self.task_fc = nn.Linear(1, dim_model, bias=False)\n",
    "\n",
    "        self.multi_en = nn.MultiheadAttention(embed_dim=dim_model, num_heads=heads_en)\n",
    "        self.ffn_en = Feed_Forward_block(dim_model)\n",
    "        self.layer_norm1 = nn.LayerNorm(dim_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, in_ex, in_cat, in_tg, in_dt, first_block=True):\n",
    "        device = in_ex.device\n",
    "\n",
    "        if first_block:\n",
    "            in_ex = self.embd_ex(in_ex)\n",
    "            in_cat = self.embd_cat(in_cat)\n",
    "\n",
    "            in_dt = in_dt.unsqueeze(-1)\n",
    "            in_dt = self.dt_fc(in_dt)\n",
    "\n",
    "            in_tg = self.embd_tg(in_tg)\n",
    "            avg_in_tg_embed = in_tg.mean(dim=2)\n",
    "            max_in_tg_embed = in_tg.max(dim=2).values\n",
    "\n",
    "            # in_task = in_task.unsqueeze(-1)\n",
    "            # in_task = self.task_fc(in_task)\n",
    "\n",
    "            # combining the embedings\n",
    "            # out = in_ex + in_cat + in_dt + (avg_in_tg_embed + max_in_tg_embed) + in_task\n",
    "            out = in_ex + in_cat + in_dt + (avg_in_tg_embed + max_in_tg_embed)\n",
    "        else:\n",
    "            out = in_ex\n",
    "\n",
    "        in_pos = get_pos(self.seq_len, device)\n",
    "        in_pos = self.embd_pos(in_pos)\n",
    "        out = out + in_pos\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "\n",
    "        # Multihead attention\n",
    "        n, _, _ = out.shape\n",
    "        out = self.layer_norm1(out)\n",
    "        skip_out = out\n",
    "        out, attn_wt = self.multi_en(out, out, out,\n",
    "                                     attn_mask=get_mask(seq_len=n, device=device))\n",
    "        out = out + skip_out\n",
    "\n",
    "        # feed forward\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.layer_norm2(out)\n",
    "        skip_out = out\n",
    "        out = self.ffn_en(out)\n",
    "        out = out + skip_out\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder_block(nn.Module):\n",
    "    \"\"\"\n",
    "    M1 = SkipConct(Multihead(LayerNorm(Qin;Kin;Vin)))\n",
    "    M2 = SkipConct(Multihead(LayerNorm(M1;O;O)))\n",
    "    L = SkipConct(FFN(LayerNorm(M2)))\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_model, total_in, total_exp, heads_de, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len - 1\n",
    "        self.embd_in = nn.Embedding(total_in, embedding_dim=dim_model)\n",
    "        # self.embd_exp = nn.Embedding(total_exp, embedding_dim=dim_model)\n",
    "        self.embd_pos = nn.Embedding(self.seq_len, embedding_dim=dim_model)\n",
    "        self.multi_de1 = nn.MultiheadAttention(embed_dim=dim_model, num_heads=heads_de)\n",
    "        self.multi_de2 = nn.MultiheadAttention(embed_dim=dim_model, num_heads=heads_de)\n",
    "        self.ffn_en = Feed_Forward_block(dim_model)\n",
    "        self.el_fc = nn.Linear(1, dim_model, bias=False)\n",
    "\n",
    "        self.layer_norm1 = nn.LayerNorm(dim_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(dim_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(dim_model)\n",
    "\n",
    "    def forward(self, in_in, in_el, en_out, first_block=True):\n",
    "        device = in_in.device\n",
    "\n",
    "        if first_block:\n",
    "            in_in = self.embd_in(in_in)\n",
    "\n",
    "            in_el = in_el.unsqueeze(-1)\n",
    "            in_el = self.el_fc(in_el)\n",
    "            # in_exp = self.embd_exp(in_exp)\n",
    "\n",
    "            # out = in_in + in_el + in_exp\n",
    "            out = in_in + in_el\n",
    "        else:\n",
    "            out = in_in\n",
    "\n",
    "        in_pos = get_pos(self.seq_len, device)\n",
    "        in_pos = self.embd_pos(in_pos)\n",
    "        out = out + in_pos\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "        n, _, _ = out.shape\n",
    "\n",
    "        out = self.layer_norm1(out)\n",
    "        skip_out = out\n",
    "        out, attn_wt = self.multi_de1(out, out, out,\n",
    "                                      attn_mask=get_mask(seq_len=n, device=device))\n",
    "        out = skip_out + out\n",
    "\n",
    "        en_out = en_out.permute(1, 0, 2)\n",
    "        en_out = self.layer_norm2(en_out)\n",
    "        skip_out = out\n",
    "        out, attn_wt = self.multi_de2(out, en_out, en_out,\n",
    "                                      attn_mask=get_mask(seq_len=n, device=device))\n",
    "        out = out + skip_out\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.layer_norm3(out)\n",
    "        skip_out = out\n",
    "        out = self.ffn_en(out)\n",
    "        out = out + skip_out\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "def get_mask(seq_len, device):\n",
    "    mask = torch.from_numpy(np.triu(np.ones((seq_len, seq_len)), k=1).astype(bool)).to(device)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_pos(seq_len, device):\n",
    "    # use sine positional embeddinds\n",
    "    return torch.arange(seq_len, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "class SAINT(nn.Module):\n",
    "    def __init__(self, dim_model, num_en, num_de, heads_en, total_ex, total_cat, total_tg, total_in, total_exp, heads_de, seq_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_en = num_en\n",
    "        self.num_de = num_de\n",
    "\n",
    "        self.encoder = get_clones(Encoder_block(dim_model, heads_en, total_ex, total_cat, total_tg, seq_len), num_en)\n",
    "        self.decoder = get_clones(Decoder_block(dim_model, total_in, total_exp, heads_de, seq_len), num_de)\n",
    "\n",
    "        self.out = nn.Linear(in_features=dim_model, out_features=1)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        in_ex = feat['in_ex']\n",
    "        in_dt = feat['in_dt']\n",
    "        in_el = feat['in_el']\n",
    "        in_tg = feat['in_tag']\n",
    "        in_cat = feat['in_cat']\n",
    "        in_in = feat['in_de']\n",
    "\n",
    "        first_block = True\n",
    "        for x in range(self.num_en):\n",
    "            if x >= 1:\n",
    "                first_block = False\n",
    "            in_ex = self.encoder[x](in_ex, in_cat, in_tg, in_dt, first_block=first_block)\n",
    "            in_cat = in_ex\n",
    "\n",
    "        first_block = True\n",
    "        for x in range(self.num_de):\n",
    "            if x >= 1:\n",
    "                first_block = False\n",
    "            in_in = self.decoder[x](in_in, in_el, en_out=in_ex, first_block=first_block)\n",
    "\n",
    "        # in_in = torch.sigmoid(self.out(in_in))\n",
    "        in_in = self.out(in_in)\n",
    "\n",
    "        return in_in.squeeze(-1)\n",
    "\n",
    "\n",
    "model_encoder = {\n",
    "    'transformer_saint_v6_2': SAINT,\n",
    "}\n",
    "\n",
    "def replace_fc(model, cfg):\n",
    "    return model\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.base_model = model_encoder[cfg['model']['backbone']](**cfg['model']['params'])\n",
    "        self.model = replace_fc(self.base_model, cfg)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class CustomTestDataset7_2(Dataset):\n",
    "    def __init__(self, df, q2p, q2tg, cfg=None):\n",
    "        super(CustomTestDataset7_2, self).__init__()\n",
    "        self.max_seq = cfg['params']['max_seq']\n",
    "        self.n_skill = cfg['params']['n_skill']\n",
    "        self.df = df\n",
    "        self.q2p = q2p\n",
    "        self.q2tg = q2tg\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def np_append(self, seq, val, dtype=int):\n",
    "        new_seq = np.zeros(self.max_seq-1, dtype=dtype)\n",
    "        new_seq[:-1] = seq[2:]\n",
    "        new_seq[-1] = val\n",
    "        return new_seq\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        row_id = row['row_id']\n",
    "        uid = row[\"user_id\"]\n",
    "        cid = row[\"content_id\"]\n",
    "        timestamp = row[\"timestamp\"]\n",
    "        et = row[\"prior_question_elapsed_time\"]\n",
    "        cid_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        dt_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        et_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        qa_seq = np.zeros(self.max_seq, dtype=int)\n",
    "        seq_len = 0\n",
    "        # cid\n",
    "        u_prev_cids = riiidFE.user_prev_ques_dict[uid]\n",
    "        seq_len = len(u_prev_cids)\n",
    "        print(seq_len)\n",
    "        if seq_len > 0:     \n",
    "            # difftime\n",
    "            difftime = riiidFE.user_timestamp_dict[uid] + [timestamp]\n",
    "            difftime = np.diff(difftime)\n",
    "            # elapsed_time\n",
    "            elapsedtime = riiidFE.user_et_dict[uid]\n",
    "            if len(elapsedtime) != 0:\n",
    "                # elapsedtime[0] = np.nan\n",
    "                elapsedtime[0] = 0\n",
    "            # answer_correctly\n",
    "            qa = np.array(list(riiidFE.user_rec_dict[uid]), dtype=np.uint8)\n",
    "            if seq_len >= self.max_seq:\n",
    "                cid_seq = u_prev_cids[-self.max_seq:]\n",
    "                dt_seq = difftime[-self.max_seq:]\n",
    "                et_seq = elapsedtime[-self.max_seq:]\n",
    "                qa_seq = qa[-self.max_seq:]\n",
    "            else:\n",
    "                cid_seq[-seq_len:] = u_prev_cids\n",
    "                dt_seq[-seq_len:] = difftime\n",
    "                et_seq[-seq_len:] = elapsedtime\n",
    "                qa_seq[-seq_len:] = qa\n",
    "        ## postprocess\n",
    "        dt_seq = np.array(dt_seq) / 60_000.   # ms -> m\n",
    "        dt_seq = np.where(dt_seq < 0, 300, dt_seq)\n",
    "        dt_seq = np.log1p(dt_seq)[1:]\n",
    "#         et_seq = np.append(et_seq[2:], [et])\n",
    "        et_seq = self.np_append(et_seq, et, dtype=float)\n",
    "        et_seq = np.array(et_seq) / 1_000.\n",
    "        et_seq = np.log1p(et_seq)\n",
    "        et_seq = np.where(np.isnan(et_seq), np.log1p(21), et_seq)\n",
    "#         cid_seq = np.append(cid_seq[2:], [cid])\n",
    "#         print(cid_seq)\n",
    "        cid_seq = self.np_append(cid_seq, cid, dtype=int)\n",
    "#         print(cid_seq)\n",
    "#         part_seq = np.array([self.q2p[i] for i in cid_seq])  \n",
    "        part_seq = self.q2p[cid_seq]\n",
    "        qtg_seq = np.zeros((self.max_seq - 1, 6), dtype=int) + 188\n",
    "        if seq_len > 0:\n",
    "            qtg_seq[-seq_len:, :] = self.q2tg[cid_seq[-seq_len:]]\n",
    "        else:\n",
    "            qtg_seq[-1, :] = self.q2tg[cid_seq[-1]]\n",
    "        qa_seq = qa_seq[1:]\n",
    "        feat = {\n",
    "            'in_ex': cid_seq,\n",
    "            'in_dt': dt_seq,\n",
    "            'in_el': et_seq,\n",
    "            'in_tag': qtg_seq,\n",
    "            'in_cat': part_seq,\n",
    "            'in_de': qa_seq,\n",
    "        }\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ = cfg['data']['valid']['params']['max_seq'] - 1\n",
    "\n",
    "def _test_epoch(model, test_dataset):\n",
    "    model.eval()\n",
    "    test_preds = np.zeros(test_dataset.__len__())\n",
    "    \n",
    "    bs = test_dataset.__len__()\n",
    "    b_in_ex = np.zeros((bs, MAX_SEQ))\n",
    "    b_in_dt = np.zeros((bs, MAX_SEQ))\n",
    "    b_in_el = np.zeros((bs, MAX_SEQ))\n",
    "    b_in_tag = np.zeros((bs, MAX_SEQ, 6))\n",
    "    b_in_cat = np.zeros((bs, MAX_SEQ))\n",
    "    b_in_de = np.zeros((bs, MAX_SEQ))\n",
    "    for i in range(bs):\n",
    "        b_in_ex[i] = test_dataset[i]['in_ex']\n",
    "        b_in_dt[i] = test_dataset[i]['in_dt']\n",
    "        b_in_el[i] = test_dataset[i]['in_el']\n",
    "        b_in_tag[i] = test_dataset[i]['in_tag']\n",
    "        b_in_cat[i] = test_dataset[i]['in_cat']\n",
    "        b_in_de[i] = test_dataset[i]['in_de']\n",
    "\n",
    "    feats = {\n",
    "        'in_ex': torch.LongTensor(b_in_ex),\n",
    "        'in_dt': torch.FloatTensor(b_in_dt),\n",
    "        'in_el': torch.FloatTensor(b_in_el),\n",
    "        'in_tag': torch.LongTensor(b_in_tag),\n",
    "        'in_cat': torch.LongTensor(b_in_cat),\n",
    "        'in_de': torch.LongTensor(b_in_de),    \n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        for k, v in feats.items():\n",
    "            feats[k] = v.to(device)\n",
    "        preds = model(feats)\n",
    "        preds = preds[:, -1]\n",
    "        test_preds = preds.sigmoid().cpu().detach().numpy()\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_tags(x): return [int(i) for i in x.split()]\n",
    "question = pd.read_csv(f'{const.INPUT_DATA_DIR}/questions.csv')\n",
    "question['tags'] = question['tags'].fillna('0').apply(prep_tags)\n",
    "question['part'] = question['part'].fillna(0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 1898.11it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_test = exp_test_df.groupby('group_num')\n",
    "\n",
    "previous_test_df = None\n",
    "for group_num, test_df in iter_test:\n",
    "    if previous_test_df is not None:\n",
    "        previous_test_df['answered_correctly'] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "        previous_test_df['user_answer'] = eval(test_df[\"prior_group_responses\"].iloc[0])\n",
    "        riiidFE.add_user_feats(previous_test_df, add_feat=False, update_dict=True, val=True)\n",
    "    \n",
    "    test_df = pd.merge(test_df, question, left_on='content_id', right_on='question_id',  how=\"left\")\n",
    "    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(False).astype('int8')\n",
    "    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].fillna(-1).astype(int)\n",
    "    \n",
    "    test_df['part'] = test_df['part'].fillna(0.0).astype('int8')\n",
    "    \n",
    "    previous_test_df = test_df.copy()\n",
    "    \n",
    "    user_feat_df = riiidFE.add_user_feats(test_df, add_feat=True, update_dict=False, val=True)\n",
    "    test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    test_df = pd.concat([test_df, user_feat_df], axis=1)\n",
    "\n",
    "    test_df = pd.concat([test_df.reset_index(drop=True),\n",
    "                                   riiidFE.content_id_df.reindex(test_df['content_id'].values).reset_index(drop=True).iloc[:, 1:]], axis=1)\n",
    "    \n",
    "    test_dataset = CustomTestDataset7_2(test_df, q2p, q2tg, cfg['data']['valid'])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['in_ex', 'in_dt', 'in_el', 'in_tag', 'in_cat', 'in_de'])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [  0,   0,   0,   0,   0,   8]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]['in_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0, 143, 140,  81,  29],\n",
       "       [  0,   0,   0,   0,   0, 125],\n",
       "       [  0,   0,   0,   0,   0,  23],\n",
       "       [  0,   0,   0,   0,   0, 180],\n",
       "       [  0,   0,   0,   0,   0,  53],\n",
       "       [  0,   0,   0,   0,   0,  43],\n",
       "       [  0,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   0,   0,  33],\n",
       "       [  0,   0,   0, 131,  93,  81],\n",
       "       [  0,   0,   0,   0,   0,  54],\n",
       "       [  0,   0,   0,   0,   0,  28],\n",
       "       [  0,   0,   0,   0,   0, 134],\n",
       "       [  0,   0,   0,   0,   0, 174],\n",
       "       [  0,   0,   0,   0,   0, 179],\n",
       "       [  0,   2, 107, 162,  81,  29],\n",
       "       [  0,   0,   0,   0,   0,  53],\n",
       "       [  0,   0,   0,   0,   0, 179],\n",
       "       [  0,   0,   0,   0,   0,  52],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0, 115],\n",
       "       [  0,   0,   0,   0,   0, 123],\n",
       "       [  0,   0,   0,   0,   0, 170],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0, 168],\n",
       "       [  0,   0,   0,   0,   0, 159],\n",
       "       [  0, 143, 176,   6,  38,  92],\n",
       "       [  0,  62,  90, 100,  38, 102],\n",
       "       [  0, 143, 176,   6,  38, 102],\n",
       "       [  0,   0,  90, 100,  38,  81],\n",
       "       [  0,   0, 143, 105,  38,  29],\n",
       "       [  0,   2,  62,  32,  81,  29],\n",
       "       [  0,   0, 143,  71,  81,  29],\n",
       "       [  0,   0, 137,  88,  38,  29],\n",
       "       [  0, 143, 114, 162,  38,  92],\n",
       "       [  0,   0, 143, 105,  38,  29],\n",
       "       [  0,   0, 143,  30,  81,  92],\n",
       "       [  0,   0, 155, 119,  92,  29],\n",
       "       [  0,   0, 148,  32,  38,  92],\n",
       "       [  0,   0,  90, 100,  38,  92],\n",
       "       [  0, 155, 163, 162,  92, 102],\n",
       "       [  0,   0, 143,  20,  38,  29],\n",
       "       [  0,  62, 155, 163,  38,  81],\n",
       "       [  0, 129, 143,  30,  38, 102],\n",
       "       [  0, 143, 140,  69,  92, 102],\n",
       "       [  0,   0, 143, 140,  81,  92],\n",
       "       [  0,   0,   0,   0,   0,  14],\n",
       "       [  0,   0,   0,   0,   0,  79],\n",
       "       [  0,   0,   0,   0,   0, 159],\n",
       "       [  0,   0,   0,   0,   0,  15],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0, 116],\n",
       "       [  0,   0,   0,   0,   0,  25],\n",
       "       [  0,   0,   0,   0,   0, 134],\n",
       "       [  0,   0,   0,   0,   0,  65],\n",
       "       [  0,   0,   0,   0,   0, 109],\n",
       "       [  0,   0,   0,   0,   0, 174],\n",
       "       [  0,   0,   0,   0,   0,  89],\n",
       "       [  0,   0,   0,   0,   0,  89],\n",
       "       [  0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0, 172],\n",
       "       [  0,   0,   0,   0,   0,  75],\n",
       "       [  0,   0,   0,   0,   0,  25],\n",
       "       [  0,   0,   0,   0,   0, 147],\n",
       "       [  0,   0,   0,   0,   0,  43],\n",
       "       [  0,   0,   0,   0,   0, 180],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0, 132],\n",
       "       [  0,   0,   0,   0,   0, 159],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0,  15],\n",
       "       [  0,   0,   0,   0,   0, 156],\n",
       "       [  0,   0,   0,   0,   0, 174],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0,  48],\n",
       "       [  0,   0,   0,   0,   0,  78],\n",
       "       [  0,   0,   0,   0,   0, 159],\n",
       "       [  0,   0,   0,   0,   0, 156],\n",
       "       [  0,   0,   0,   0,   0,  26],\n",
       "       [  0,   0,   0,   0,   0,  53],\n",
       "       [  0,   0,   0,   0,   0,  65],\n",
       "       [  0,   0,   0,   0,   0, 166],\n",
       "       [  0,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   0,   0, 166],\n",
       "       [  0,   0,   0,   0,   0,  26],\n",
       "       [  0,   0,   0,   0,   0,  26],\n",
       "       [  0,   0,   0,   0,   0, 132],\n",
       "       [  0,   0,   0,   0,   0, 132],\n",
       "       [  0,   0, 138,  41,  81,  29],\n",
       "       [  0,   0, 143, 114,  38, 102],\n",
       "       [  0,   2, 107,  62,  29, 102],\n",
       "       [  0,   0, 143, 114,  38,  81],\n",
       "       [  0,   0, 155, 119,  38,  29],\n",
       "       [  0,   0, 143, 105,  92, 102],\n",
       "       [  0,   0, 137, 142,  92, 102],\n",
       "       [  0,   0, 148,  32,  38,  29],\n",
       "       [  0,   0, 143, 176,  81,  92],\n",
       "       [  0, 137, 142, 162,  38,  92],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   0,   0,  55],\n",
       "       [  0,   0,   0,   0,   0, 166],\n",
       "       [  0,   0,   0,   0,   0,  52],\n",
       "       [  0,   0,   0,   0,   0,  14],\n",
       "       [  0,   0,   0,   0,   0, 180],\n",
       "       [  0,   0,   0,   0,   0, 125],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0, 109],\n",
       "       [  0, 129, 143, 176,  38,  29],\n",
       "       [  0,   0, 143,  71,  38,  29],\n",
       "       [  0,  62,  17,  56,  38,  29],\n",
       "       [  0, 143,  69,  20,  92, 102],\n",
       "       [  0,  62, 148,  32,  92, 102],\n",
       "       [  0,   0, 143, 105,  92,  29],\n",
       "       [  0,   0,  90, 100,  81,  92],\n",
       "       [  0,   0,  90, 100,  38,  81],\n",
       "       [  0,   0, 148,  32,  38, 102],\n",
       "       [  0,   0, 143, 140,  81,  92],\n",
       "       [  0,   0,   0,   0,   0,  96]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[3]['in_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [188, 188, 188, 188, 188, 188],\n",
       "       [  0,   0,  90, 100,  81,  92],\n",
       "       [  0,   0, 143,  30,  92, 102],\n",
       "       [  0,   0,   0,   0,   0, 181],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0,  53],\n",
       "       [  0,   0,   0,   0,   0,  53],\n",
       "       [  0,   0,   0,   0,   0, 170],\n",
       "       [  0,   0,   0,   0,   0,  55],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0, 167],\n",
       "       [  0,   0,  17,  56,  38,  29],\n",
       "       [  0,   0, 143, 114,  38, 102],\n",
       "       [  0,   0, 143,  20,  38, 102],\n",
       "       [  0,   0, 155, 119,  81,  92],\n",
       "       [  0,   0, 148,  32,  38,  92],\n",
       "       [  0,  62, 155, 119,  38, 102],\n",
       "       [  0,   0, 143, 141,  38,  92],\n",
       "       [  0,   0, 137,  88,  38,  29],\n",
       "       [  0,   0,  17,  56,  38,  92],\n",
       "       [  0, 129, 143, 176,  38, 102],\n",
       "       [  0,   0,   0,   0,   0,  45],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0, 170],\n",
       "       [  0,   0,   0,   0,   0, 109],\n",
       "       [  0,   0,   0,   0,   0, 168],\n",
       "       [  0,   0,   0,   0,   0, 127],\n",
       "       [  0,   0,   0,   0,   0, 151],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0,  95],\n",
       "       [  0,   0,   0,   0,   0, 147],\n",
       "       [  0,   0,   0,   0,   0,  15],\n",
       "       [  0,   0,   0,   0,   0, 173],\n",
       "       [  0,   0,   0,   0,   0,  31],\n",
       "       [  0,   0,   0,   0,   0, 108],\n",
       "       [  0,   0,   0,   0,   0, 175],\n",
       "       [  0,   0,   0,   0,   0, 166],\n",
       "       [  0,   0,   0,   0,   0, 127],\n",
       "       [  0,   0,   0,   0,   0,  91],\n",
       "       [  0,   0,   0,   0,   0,  23],\n",
       "       [  0,   0,   0,   0,   0, 116],\n",
       "       [  0, 129, 143,  30,  81,  29],\n",
       "       [  0,   0, 155, 163,  92,  29],\n",
       "       [  0, 138,  41, 162,  92, 102],\n",
       "       [  0,   0, 138,  41,  92, 102],\n",
       "       [  0,  69, 137,  88,  81,  29],\n",
       "       [  0,   0, 155, 119,  81,  92],\n",
       "       [  0,   0,  17,  56,  29, 102],\n",
       "       [  0,  17,  56, 162,  38, 102],\n",
       "       [  0,   0,   2, 107,  92, 102],\n",
       "       [  0,   0, 143, 114,  38,  29],\n",
       "       [  0,   0,   0,   0,   0, 123],\n",
       "       [  0,   0,   0,   0,   0, 116],\n",
       "       [  0,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   0,   0,  79],\n",
       "       [  0,   0,   0,   0,   0,  73],\n",
       "       [  0,   0,   0,   0,   0, 166],\n",
       "       [  0,   0,   0,   0,   0,  89],\n",
       "       [  0,   0,   0,   0,   0,  96],\n",
       "       [  0,   0,   0,   0,   0, 124],\n",
       "       [  0,   0,   0,   0,   0, 134],\n",
       "       [  0, 137,  88, 162,  81,  92],\n",
       "       [  0, 155, 119, 162,  38, 102],\n",
       "       [  0,   0, 138,  41,  38, 102],\n",
       "       [  0,   0, 143,  20,  81,  92],\n",
       "       [  0,   0, 143, 105,  81,  92],\n",
       "       [  0,   0,  17,  56,  38,  81],\n",
       "       [  0, 155, 119, 162,  81,  92],\n",
       "       [  0,   0,  90, 142,  92,  29],\n",
       "       [  0, 155, 163, 162,  92, 102],\n",
       "       [  0,   0, 155, 163,  92,  29],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0,  80],\n",
       "       [  0,   0,   0,   0,   0, 180],\n",
       "       [  0,   0,   0,   0,   0, 177],\n",
       "       [  0,   0,   0,   0,   0,   8],\n",
       "       [  0,   0,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   0,   0, 182],\n",
       "       [  0,   0,   0,   0,   0,  15],\n",
       "       [  0,   0,   2, 107,  38,  92]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10]['in_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.array(list(q2p.values()))[test_dataset[3]['in_ex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[3]['in_ex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df[train_df['user_id'] == 288641214].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log1p((62798072960 - 62725820527) / 60_000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "miniconda3-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
