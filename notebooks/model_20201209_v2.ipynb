{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver_dir = Path('./model_20201209_lightgbm_v2')\n",
    "ver_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pickle = '../folds/cv1_train.pickle'\n",
    "valid_pickle = '../folds/cv1_valid.pickle'\n",
    "question_file = '../data/input/questions.csv'\n",
    "debug = False\n",
    "validaten_flg = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_left_merge(df1, df2, on):\n",
    "    df2.index = df2[on]\n",
    "\n",
    "    merged_df = pd.concat([\n",
    "        df1.reset_index(drop=True),\n",
    "        df2.reindex(df1[on].values).reset_index(drop=True).drop(on, axis=1)\n",
    "    ], axis=1)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# funcs for user stats with loop\n",
    "def add_user_feats(df, answered_correctly_sum_u_dict, count_u_dict, prior_q_dict, attempt_cc_dict, attempt_cb_dict, answered_correctly_roll_dict):\n",
    "    acsu = np.zeros(len(df), dtype=np.int32)\n",
    "    cu = np.zeros(len(df), dtype=np.int32)\n",
    "    pcf = np.zeros(len(df), dtype=np.int32)\n",
    "    acc = np.zeros(len(df), dtype=np.int32)\n",
    "    acb = np.zeros(len(df), dtype=np.int32)\n",
    "    acr3 = np.zeros(len(df), dtype=np.float32)\n",
    "    acr5 = np.zeros(len(df), dtype=np.float32)\n",
    "    acr7 = np.zeros(len(df), dtype=np.float32)\n",
    "    acr9 = np.zeros(len(df), dtype=np.float32)\n",
    "    \n",
    "    s = 1e-3\n",
    "    \n",
    "    default_array = np.zeros(9, dtype=np.int32)\n",
    "\n",
    "    for cnt, row in enumerate(tqdm(df[['user_id', 'content_id', 'content_id_bin', 'content_class_id', 'answered_correctly']].values)):\n",
    "        acsu[cnt] = answered_correctly_sum_u_dict.setdefault(row[0], 0)\n",
    "        cu[cnt] = count_u_dict.setdefault(row[0], 0)\n",
    "        if row[1] == prior_q_dict.setdefault(row[0], -1):\n",
    "            pcf[cnt] = 1\n",
    "        else:\n",
    "            pcf[cnt] = 0\n",
    "        \n",
    "        acc[cnt] = attempt_cc_dict.setdefault(row[0], {}).setdefault(row[3], 1)\n",
    "        acb[cnt] = attempt_cb_dict.setdefault(row[0], {}).setdefault(row[2], 1)\n",
    "        \n",
    "        acr = answered_correctly_roll_dict.setdefault(row[0], default_array)\n",
    "        acr3 = np.mean(acr[:3])\n",
    "        acr5 = np.mean(acr[:5])\n",
    "        acr7 = np.mean(acr[:7])\n",
    "        acr9[cnt] = np.mean(acr)\n",
    "\n",
    "        answered_correctly_sum_u_dict[row[0]] += row[4]\n",
    "        prior_q_dict[row[0]] = row[1]\n",
    "        count_u_dict[row[0]] += 1\n",
    "        attempt_cc_dict[row[0]][row[3]] += 1\n",
    "        attempt_cb_dict[row[0]][row[2]] += 1\n",
    "        \n",
    "        user_ac_roll = answered_correctly_roll_dict[row[0]]\n",
    "        user_ac_roll = np.delete(user_ac_roll, 0)\n",
    "        user_ac_roll = np.append(user_ac_roll, row[4])\n",
    "        answered_correctly_roll_dict[row[0]] = user_ac_roll\n",
    "\n",
    "    user_feats_df = pd.DataFrame({\n",
    "        'answered_correctly_sum_u':acsu,\n",
    "        'count_u':cu,\n",
    "        'equal_prior_question_flag': pcf,\n",
    "        'attempt_cc': acc,\n",
    "        'attempt_cb': acb,\n",
    "        'answered_correctly_roll3': acr3,\n",
    "        'answered_correctly_roll5': acr5,\n",
    "        'answered_correctly_roll7': acr7,\n",
    "        'answered_correctly_roll9': acr9\n",
    "    })\n",
    "    user_feats_df['answered_correctly_avg_u'] = user_feats_df['answered_correctly_sum_u'] / user_feats_df['count_u']\n",
    "    user_feats_df['acr3_div_acr9'] = user_feats_df['answered_correctly_roll3'] / (user_feats_df['answered_correctly_roll9'] + s)\n",
    "    user_feats_df['acr5_div_acr9'] = user_feats_df['answered_correctly_roll5'] / (user_feats_df['answered_correctly_roll9'] + s)\n",
    "    user_feats_df['acr7_div_acr9'] = user_feats_df['answered_correctly_roll7'] / (user_feats_df['answered_correctly_roll9'] + s)\n",
    "    user_feats_df['acr3_div_acr5'] = user_feats_df['answered_correctly_roll3'] / (user_feats_df['answered_correctly_roll5'] + s)\n",
    "    user_feats_df['acr5_div_acr7'] = user_feats_df['answered_correctly_roll5'] / (user_feats_df['answered_correctly_roll7'] + s)\n",
    "    user_feats_df['acr3_div_acr7'] = user_feats_df['answered_correctly_roll3'] / (user_feats_df['answered_correctly_roll7'] + s)\n",
    "    df = pd.concat([df, user_feats_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "feld_needed = [\n",
    "    'row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id', 'answered_correctly',\n",
    "    'prior_question_elapsed_time', 'prior_question_had_explanation', 'task_container_id'\n",
    "]\n",
    "train = pd.read_pickle(train_pickle)[feld_needed]\n",
    "valid = pd.read_pickle(valid_pickle)[feld_needed]\n",
    "if debug:\n",
    "    train = train[:1_000_000]\n",
    "    valid = valid[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')\n",
    "from utils import DataHandler\n",
    "from cuml.cluster import KMeans\n",
    "\n",
    "dh  =DataHandler()\n",
    "\n",
    "tsne_encoder_0 = dh.load('../data/processed/tsne_encoder_0.pkl')\n",
    "tsne_encoder_1 = dh.load('../data/processed/tsne_encoder_1.pkl')\n",
    "\n",
    "tsne_df = pd.DataFrame({'content_id': tsne_encoder_0.keys(), 'tsne0': tsne_encoder_0.values()})\n",
    "tsne_df['tsne1'] = tsne_df['content_id'].map(tsne_encoder_1)\n",
    "tsne_df['content_id'] = tsne_df['content_id'].astype(np.int32)\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=1000, max_iter=300, init='scalable-k-means++')\n",
    "kmeans.fit(tsne_df[['tsne0', 'tsne1']])\n",
    "tsne_df['content_class_id'] = kmeans.predict(tsne_df[['tsne0', 'tsne1']])\n",
    "\n",
    "\n",
    "for col in tsne_df.columns[1:]:\n",
    "    le = dict(tsne_df[['content_id', col]].values)\n",
    "\n",
    "    train[col] = train['content_id'].map(le).fillna(-999)\n",
    "    valid[col] = valid['content_id'].map(le).fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_count_df = train['user_id'].value_counts().reset_index()\n",
    "# user_count_df.columns = ['user_id', 'count_num']\n",
    "# user_count_df['count_bin'] = pd.cut(user_count_df['count_num'], 200, labels=False)\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=2020)\n",
    "\n",
    "# fold_df = pd.DataFrame(index=user_count_df.index)\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(kfold.split(user_count_df, user_count_df['count_bin'])):\n",
    "#     fold_df[f'fold_{fold_}'] = 0\n",
    "#     fold_df.loc[val_idx, f'fold_{fold_}'] += 1\n",
    "\n",
    "# drop_train_users = user_count_df.loc[fold_df[fold_df['fold_0'] == 1].index, 'user_id'].values\n",
    "# train = train[~train['user_id'].isin(drop_train_users)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_c_each_answer = pd.crosstab(index=train['content_id'],\n",
    "                                                        columns=train['answered_correctly'])\n",
    "count_c_each_answer.columns = ['lecture', 'ans_false', 'ans_true']\n",
    "count_c_each_answer['rate_lecture'] = count_c_each_answer['lecture'] / count_c_each_answer.values.sum(axis=1)\n",
    "c2rl = dict(count_c_each_answer['rate_lecture'])\n",
    "\n",
    "train = train.loc[train.content_type_id == False].reset_index(drop=True)\n",
    "valid = valid.loc[valid.content_type_id == False].reset_index(drop=True)\n",
    "\n",
    "whole = pd.concat([train[['content_id']], valid[['content_id']]], axis=0)\n",
    "count_content_dict = whole['content_id'].value_counts()\n",
    "train['count_c'] = train['content_id'].map(count_content_dict)\n",
    "valid['count_c'] = valid['content_id'].map(count_content_dict)\n",
    "\n",
    "del whole; gc.collect()\n",
    "\n",
    "\n",
    "train['content_id_bin'] = train['content_id'] // 10\n",
    "valid['content_id_bin'] = valid['content_id'] // 10\n",
    "\n",
    "\n",
    "\n",
    "questions_df = pd.read_csv(question_file)[['question_id', 'part']]\n",
    "q2p = dict(questions_df.values)\n",
    "\n",
    "train['part'] = train['content_id'].map(q2p)\n",
    "valid['part'] = valid['content_id'].map(q2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3e1029cffd4c61af0a689c0e255af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=96817414.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c81e953e934536ab57e5a42f1e76fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2453886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# user stats features with loops\n",
    "answered_correctly_sum_u_dict = {}\n",
    "count_u_dict = {}\n",
    "prior_q_dict = {}\n",
    "attempt_cc_dict = {}\n",
    "attempt_cb_dict = {}\n",
    "answered_correctly_roll_dict = {}\n",
    "\n",
    "train = add_user_feats(train, answered_correctly_sum_u_dict, count_u_dict, prior_q_dict, attempt_cc_dict, attempt_cb_dict, answered_correctly_roll_dict)\n",
    "valid = add_user_feats(valid, answered_correctly_sum_u_dict, count_u_dict, prior_q_dict, attempt_cc_dict, attempt_cb_dict, answered_correctly_roll_dict)\n",
    "\n",
    "# fill with mean value for prior_question_elapsed_time\n",
    "# note that `train.prior_question_elapsed_time.mean()` dose not work!\n",
    "# please refer https://www.kaggle.com/its7171/can-we-trust-pandas-mean for detail.\n",
    "# prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n",
    "# train['prior_question_elapsed_time_mean'] = train.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "# valid['prior_question_elapsed_time_mean'] = valid.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "\n",
    "# use only last 30M training data for limited memory on kaggle env.\n",
    "#train = train[-30000000:]\n",
    "\n",
    "# changing dtype to avoid lightgbm error\n",
    "train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "sys.path.append('../src')\n",
    "from factory import get_fold\n",
    "from make_features.feature_utils import TargetEncoding\n",
    "\n",
    "cfg = edict({\n",
    "    'name': 'KFold',\n",
    "    'params': {\n",
    "        'n_splits': 5,\n",
    "        'shuffle': True,\n",
    "        'random_state': 0,\n",
    "    },\n",
    "    'split': {\n",
    "        'y': 'user_id',\n",
    "        'groups': None\n",
    "    },\n",
    "    'weight': 'average'\n",
    "})\n",
    "\n",
    "\n",
    "fold_df = get_fold(cfg, train)\n",
    "\n",
    "col = 'content_id'\n",
    "te = TargetEncoding(fold_df)\n",
    "train[f'te_{col}_by_answered_correctly'] = te.fit_transform(train[col], train['answered_correctly'])\n",
    "valid[f'te_{col}_by_answered_correctly'] = te.transform(valid[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TARGET = 'answered_correctly'\n",
    "FEATS = [\n",
    "    'answered_correctly_avg_u', 'answered_correctly_sum_u', 'count_u', 'equal_prior_question_flag',\n",
    "    'te_content_id_by_answered_correctly', 'part', 'prior_question_had_explanation', \n",
    "    'prior_question_elapsed_time', 'attempt_cc', 'attempt_cb', 'user_id', 'content_id_bin', 'tsne0', 'tsne1',\n",
    "    'answered_correctly_roll3', 'answered_correctly_roll5', 'answered_correctly_roll7', 'answered_correctly_roll9',\n",
    "    'acr3_div_acr9', 'acr5_div_acr9', 'acr7_div_acr9', 'acr3_div_acr5', 'acr5_div_acr7', 'acr3_div_acr7'\n",
    "]\n",
    "\n",
    "dro_cols = list(set(train.columns) - set(FEATS))\n",
    "y_tr = train[TARGET]\n",
    "y_va = valid[TARGET]\n",
    "train.drop(dro_cols, axis=1, inplace=True)\n",
    "valid.drop(dro_cols, axis=1, inplace=True)\n",
    "_=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train[FEATS], y_tr)\n",
    "lgb_valid = lgb.Dataset(valid[FEATS], y_va)\n",
    "del train, y_tr\n",
    "_=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.3,\n",
    "#     'num_leaves': 32,\n",
    "#     'min_child_samples': 20,\n",
    "#     'feature_fraction': 0.8,\n",
    "#     'bagging_fraction': 0.3,\n",
    "#     'bagging_freq': 1,\n",
    "#     'bagging_seed': 11,\n",
    "#     'max_bin': 255,\n",
    "#     'verbose': -1,\n",
    "#     'nthread': -1,\n",
    "    'seed': 2020,\n",
    "#     'first_metric_only': True\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_valid],\n",
    "                    verbose_eval=10,\n",
    "                    num_boost_round=100,\n",
    "                    early_stopping_rounds=10\n",
    "                )\n",
    "print('auc:', roc_auc_score(y_va, model.predict(valid[FEATS])))\n",
    "_ = lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(obj, f_name):\n",
    "    with open(f_name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "if debug:\n",
    "    save_pickle(model, ver_dir / f'{str(ver_dir)}.pkl')\n",
    "    save_pickle(answered_correctly_sum_u_dict, ver_dir / 'debug_answered_correctly_sum_u_dict.pkl')\n",
    "    save_pickle(count_u_dict, ver_dir / 'debug_count_u_dict.pkl')\n",
    "#     save_pickle(count_c_each_u_dict, 'debug_count_c_each_u_dict.pkl')\n",
    "    save_pickle(prior_q_dict, ver_dir / 'debug_prior_q_dict.pkl')\n",
    "    save_pickle(attempt_cb_dict, ver_dir / 'debug_attempt_cb_dict.pkl')\n",
    "    save_pickle(te.encoder, ver_dir / 'debug_te_encoder.pkl')\n",
    "    save_pickle(answered_correctly_roll_dict, ver_dir / 'debug_answered_correctly_roll_dict.pkl')\n",
    "else:\n",
    "    save_pickle(model, ver_dir / f'{str(ver_dir)}.pkl')\n",
    "    save_pickle(answered_correctly_sum_u_dict, ver_dir / 'answered_correctly_sum_u_dict.pkl')\n",
    "    save_pickle(count_u_dict, ver_dir / 'count_u_dict.pkl')\n",
    "#     save_pickle(count_c_each_u_dict, 'count_c_each_u_dict.pkl')\n",
    "    save_pickle(prior_q_dict, ver_dir / 'prior_q_dict.pkl')\n",
    "    save_pickle(attempt_cb_dict, ver_dir / 'attempt_cb_dict.pkl')\n",
    "    save_pickle(te.encoder, ver_dir / 'te_encoder.pkl')\n",
    "    save_pickle(answered_correctly_roll_dict, ver_dir / 'answered_correctly_roll_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "miniconda3-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
